{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_ads = pd.read_json('Testfil_FINAL_2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sentiment score for 'god': 0.2792\n",
      "Mean sentiment score for 'analytisk': 0.0810\n",
      "Mean sentiment score for 'förmåga': 0.1102\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.text import Text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import string\n",
    "\n",
    "# Load the sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a list to store the sentiment scores\n",
    "sentiment_scores = []\n",
    "\n",
    "# Create a list of all the job ad descriptions\n",
    "texts = [t.lower() for t in job_ads['description_text'].tolist()]\n",
    "\n",
    "# Create a stop_words set\n",
    "stop_words = set(stopwords.words('swedish'))\n",
    "\n",
    "# Tokenize the descriptions and remove stopwords\n",
    "tokens = [[w for w in word_tokenize(d) if not w in stop_words] for d in texts]\n",
    "\n",
    "# Create an NLTK Text object from the tokens\n",
    "text = Text([t for d in tokens for t in d])\n",
    "\n",
    "# Define the keywords to search for\n",
    "keywords = ['god', 'analytisk', 'förmåga']\n",
    "\n",
    "# Define the number of characters to show before and after the keyword\n",
    "window_size = 3\n",
    "\n",
    "# Iterate through each keyword\n",
    "for keyword in keywords:\n",
    "    # Get the indices of all occurrences of the keyword\n",
    "    indices = [i for i, w in enumerate(text) if w == keyword]\n",
    "\n",
    "    # Define a list to store the KWIC for the keyword\n",
    "    kwic = []\n",
    "\n",
    "    # Generate the KWIC for each occurrence of the keyword\n",
    "    for i in indices:\n",
    "        left = ' '.join(text[i-window_size:i])\n",
    "        right = ' '.join(text[i+1:i+window_size+1])\n",
    "        #print(left, text[i], right)\n",
    "        #print('-' * 50)\n",
    "        kwic.append(left + ' ' + keyword + ' ' + right)\n",
    "    \n",
    "    # Define a list to store the sentiment scores for the KWIC\n",
    "    keyword_sentiment_scores = []\n",
    "\n",
    "    # Loop through each KWIC and get the sentiment score\n",
    "    for k in kwic:\n",
    "        # Remove punctuations and stopwords from the KWIC\n",
    "        k = k.translate(str.maketrans('', '', string.punctuation))\n",
    "        k = [word for word in k.split() if word not in stop_words]\n",
    "\n",
    "        # Check if KWIC is not empty\n",
    "        if k:\n",
    "            # Get the sentiment score for the KWIC\n",
    "            sentiment_score = sia.polarity_scores(' '.join(k))['compound']\n",
    "            keyword_sentiment_scores.append(sentiment_score)\n",
    "\n",
    "    # Calculate the mean sentiment score for the keyword\n",
    "    if keyword_sentiment_scores:\n",
    "        keyword_mean_sentiment_score = sum(keyword_sentiment_scores) / len(keyword_sentiment_scores)\n",
    "        sentiment_scores.append(keyword_mean_sentiment_score)\n",
    "\n",
    "        # Print the mean sentiment score for the keyword\n",
    "        print(f\"Mean sentiment score for '{keyword}': {keyword_mean_sentiment_score:.4f}\")\n",
    "    else:\n",
    "        print(f\"No sentiment score found for '{keyword}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequently occurring keywords:\n",
      "kommer: 11207\n",
      "erfarenhet: 7553\n",
      "arbeta: 7254\n",
      "hos: 6544\n",
      "söker: 6240\n",
      "vill: 5708\n",
      "samt: 5562\n",
      "tjänsten: 5254\n",
      "kunder: 5049\n",
      "in: 4581\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Identify the frequently occurring keywords in the KWIC output\n",
    "keywords = [w for w in text if w != keyword and w.isalpha()]\n",
    "keywords_counter = Counter(keywords)\n",
    "print('Frequently occurring keywords:')\n",
    "for word, count in keywords_counter.most_common(10):\n",
    "    print(f'{word}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword: stark, Sentiment score: -0.15\n",
      "Keyword: drivkraft, Sentiment score: 0.06\n",
      "Keyword: chef, Sentiment score: 0.03\n",
      "Keyword: analys, Sentiment score: 0.03\n",
      "Keyword: analytisk, Sentiment score: 0.13\n",
      "Keyword: driven, Sentiment score: 0.15\n",
      "Keyword: individer, Sentiment score: 0.11\n",
      "Keyword: beslut, Sentiment score: 0.05\n",
      "Keyword: kompetent, Sentiment score: 0.04\n",
      "Keyword: självständig, Sentiment score: 0.11\n",
      "Average sentiment score: 0.05688113563153881\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk import word_tokenize\n",
    "from nltk.text import Text\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load the sentiment analyzers\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a list to store the sentiment scores\n",
    "sentiment_scores = []\n",
    "\n",
    "# Create a list of all the job ad descriptions\n",
    "texts = [t.lower() for t in job_ads['description_text'].tolist()]\n",
    "\n",
    "# Create a stop_words set\n",
    "stop_words = set(stopwords.words('swedish'))\n",
    "\n",
    "# Tokenize the descriptions and remove stopwords\n",
    "tokens = [[w for w in word_tokenize(d) if not w in stop_words] for d in texts]\n",
    "\n",
    "# Create an NLTK Text object from the tokens\n",
    "text = Text([t for d in tokens for t in d])\n",
    "\n",
    "# Define the keywords to search for\n",
    "keywords = ['stark',\n",
    "'drivkraft',\n",
    "'chef',\n",
    "'analys',\n",
    "'analytisk',\n",
    "'driven',\n",
    "'individer',\n",
    "'beslut',\n",
    "'kompetent',\n",
    "'självständig']\n",
    "\n",
    "# Define the number of characters to show before and after the keyword\n",
    "window_size = 15\n",
    "\n",
    "# Iterate through each keyword\n",
    "for keyword in keywords:\n",
    "    # Get the indices of all occurrences of the keyword\n",
    "    indices = [i for i, w in enumerate(text) if w == keyword]\n",
    "\n",
    "    # Define a list to store the KWIC for the keyword\n",
    "    kwic = []\n",
    "\n",
    "    # Generate the KWIC for each occurrence of the keyword\n",
    "    for i in indices:\n",
    "        left = ' '.join(text[i-window_size:i])\n",
    "        right = ' '.join(text[i+1:i+window_size+1])\n",
    "        kwic.append(left + ' ' + keyword + ' ' + right)\n",
    "\n",
    "    # Calculate the sentiment score for the KWICs\n",
    "    kwic_sentiment_scores = []\n",
    "    for kwic_text in kwic:\n",
    "        sia_scores = sia.polarity_scores(kwic_text)\n",
    "        tb_scores = TextBlob(kwic_text).sentiment\n",
    "        # Combine the sentiment scores from the two analyzers\n",
    "        compound_score = sia_scores['compound'] + tb_scores.polarity\n",
    "        kwic_sentiment_scores.append(compound_score)\n",
    "\n",
    "    # Calculate the average sentiment score for the keyword\n",
    "    avg_sentiment = sum(kwic_sentiment_scores) / len(kwic_sentiment_scores)\n",
    "    sentiment_scores.append(avg_sentiment)\n",
    "    print(f\"Keyword: {keyword}, Sentiment score: {avg_sentiment:.2f}\")\n",
    "\n",
    "# Calculate the average sentiment score\n",
    "avg_sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "print(\"Average sentiment score:\", avg_sentiment_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
